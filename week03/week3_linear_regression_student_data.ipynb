{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"3주차: 선형 회귀 전체 파이프라인 (학생 학습 데이터 버전).\n",
    "\n",
    "3주차 차시 1~3에서 다루는 선형 회귀(Linear Regression) 실습 코드입니다.\n",
    "\n",
    "데이터: student_learning_data_kr.csv (학생 학습 활동 → 시험점수 예측)\n",
    "\n",
    "Contents:\n",
    "    1. 데이터 로드 및 탐색\n",
    "    2. 전처리 — 변수 유형 정의 및 표준화\n",
    "    3. 피처(X)와 타겟(y) 분리\n",
    "    4. 훈련/테스트 분리\n",
    "    5. 선형 회귀 모델 생성, 학습, 예측\n",
    "    6. 회귀 평가지표 계산 (MSE, RMSE, R²)\n",
    "    7. 학습된 계수 및 절편 해석\n",
    "    8. 다중공선성 점검\n",
    "    9. 훈련/테스트 성능 비교\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교육문제해결형 머신러닝 — 3주차 실습\n",
    "\n",
    "## 학생 학습 데이터를 활용한 시험점수 예측: 선형 회귀\n",
    "\n",
    "| 항목 | 내용 |\n",
    "|------|------|\n",
    "| **데이터** | `student_learning_data_kr.csv` (학생 학습 데이터 14,003건) |\n",
    "| **피처(X)** | 주당학습시간, 출석률, 나이, 온라인강좌수, 과제완료율 (수치형 5개) |\n",
    "| **타겟(y)** | 시험점수 (40~100점, 연속형) — **회귀(Regression)** 문제 |\n",
    "| **모델** | LinearRegression |\n",
    "| **평가지표** | MSE · RMSE · R² |\n",
    "| **핵심 패턴** | `model → fit → predict → score` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 차시 1 핵심 요약 (이론)\n",
    "\n",
    "- 선형 회귀 목표: **연속형 숫자(시험점수)** 를 예측하는 것\n",
    "- 모델 수식: `ŷ = w₁x₁ + w₂x₂ + … + wₙxₙ + b`\n",
    "- 계수(w): 각 피처가 타겟에 미치는 **영향력**\n",
    "- 절편(b): 모든 피처가 0일 때의 **기준값**\n",
    "- 학습 원리: **오차(잔차)를 최소화**하도록 w, b를 조정\n",
    "\n",
    "| 분류 vs 회귀 | 분류 (1~2주차) | 회귀 (3주차) |\n",
    "|:---:|:---:|:---:|\n",
    "| **타겟** | 범주 (A/B/C/D) | 연속 숫자 (점수) |\n",
    "| **평가** | 정확도 (Accuracy) | MSE · RMSE · R² |\n",
    "| **예시 모델** | k-NN, DecisionTree | LinearRegression |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"pandas:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2. 데이터 로드 및 탐색\n",
    "\n",
    "- **데이터**: `student_learning_data_kr.csv`\n",
    "- **피처 (14개 컬럼 중 5개 수치형 사용)**:\n",
    "  - 주당학습시간, 출석률, 나이, 온라인강좌수, 과제완료율\n",
    "- **타겟**: `시험점수` (40~100점 범위의 연속형 숫자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 로드\n",
    "url = \"https://raw.githubusercontent.com/SJ-EduLab/ML-for-Education/main/week01/student_learning_data_kr.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(f\"데이터 shape: {df.shape[0]}행 × {df.shape[1]}열\")\n",
    "print(f\"컬럼 목록: {df.columns.tolist()}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 변수 기술 통계\n",
    "print(\"=== 수치형 변수 기술 통계 ===\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3. 데이터 전처리\n",
    "\n",
    "### 3.1 변수 유형 정의\n",
    "\n",
    "| 유형 | 변수 |\n",
    "|------|------|\n",
    "| 연속형 (수치) | 주당학습시간, 출석률, 나이, 온라인강좌수, 과제완료율, 시험점수 |\n",
    "| 순서형 | 학습동기, 스트레스수준 |\n",
    "| 이진형 | 비교과활동, 인터넷접근, 성별, 토론참여 |\n",
    "| 명목형 | 선호학습유형 |\n",
    "\n",
    "이번 실습에서는 **수치형 피처 5개**(시험점수 제외)만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 유형 정의\n",
    "continuous = [\n",
    "    \"주당학습시간\", \"출석률\", \"나이\", \"온라인강좌수\", \"과제완료율\", \"시험점수\",\n",
    "]\n",
    "target = \"시험점수\"\n",
    "\n",
    "# 피처용 연속형 변수 (타겟 제외)\n",
    "feature_continuous = [col for col in continuous if col != target]\n",
    "\n",
    "print(f\"피처로 사용할 연속형 변수 (타겟 제외): {feature_continuous}\")\n",
    "print(f\"타겟 변수: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 피처 표준화 (StandardScaler)\n",
    "\n",
    "- `StandardScaler`: 평균=0, 표준편차=1로 변환\n",
    "- 피처 간 스케일 차이를 제거 → 계수 비교 가능성 향상\n",
    "- **타겟 변수(시험점수)는 스케일링하지 않음** (원래 점수 단위 유지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"연속형 피처를 StandardScaler로 표준화한다.\n",
    "\n",
    "타겟 변수(시험점수)는 원래 단위를 유지하기 위해 스케일링 대상에서\n",
    "제외한다.\n",
    "\"\"\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 타겟 제외한 연속형 피처만 스케일링\n",
    "df[feature_continuous] = scaler.fit_transform(df[feature_continuous])\n",
    "\n",
    "print(\"스케일링 후 기술 통계 (피처):\")\n",
    "display(df[feature_continuous].describe().round(2))\n",
    "\n",
    "print(f\"\\n⚠ 타겟 변수(시험점수)는 원래 단위 유지:\")\n",
    "print(f\"  범위: {df[target].min()} ~ {df[target].max()}점\")\n",
    "print(f\"  평균: {df[target].mean():.2f}점\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4. 피처(X)와 타겟(y) 분리\n",
    "\n",
    "- **피처(X)**: 모델에게 제공하는 입력 (주당학습시간, 출석률, 나이, 온라인강좌수, 과제완료율)\n",
    "- **타겟(y)**: 모델이 맞춰야 하는 출력 (시험점수)\n",
    "\n",
    "이번 실습의 타겟은 **시험점수(연속형 숫자)** — 따라서 **회귀** 문제이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처(X)와 타겟(y) 분리\n",
    "feature_columns = feature_continuous\n",
    "target_column = target\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "print(f\"선택된 피처: {feature_columns}\")\n",
    "print(f\"타겟 변수: {target_column}\")\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# 결측치 확인\n",
    "print(f\"\\n결측치 확인:\")\n",
    "print(X.isnull().sum())\n",
    "print(f\"타겟 결측치: {y.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5. 훈련/테스트 세트 분리\n",
    "\n",
    "- `test_size=0.3`: 전체의 30%를 테스트 세트로 분리\n",
    "- `random_state=42`: 재현성(reproducibility)을 위한 랜덤 시드 고정\n",
    "\n",
    "**왜 나누는가?** → 모델의 **일반화 성능**(새 데이터에서의 진짜 실력)을 측정하기 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"훈련 세트: {X_train.shape[0]:,}개\")\n",
    "print(f\"테스트 세트: {X_test.shape[0]:,}개\")\n",
    "print(f\"분리 비율: {X_train.shape[0]/len(X)*100:.1f}% 훈련, {X_test.shape[0]/len(X)*100:.1f}% 테스트\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6. 선형 회귀 모델 생성 · 학습 · 예측\n",
    "\n",
    "scikit-learn 핵심 3줄 패턴 (1주차 복습):\n",
    "1. `model = LinearRegression()` — 모델 준비\n",
    "2. `model.fit(X_train, y_train)` — 훈련 데이터로 패턴 학습\n",
    "3. `model.predict(X_test)` — 새 데이터에 대해 예측\n",
    "\n",
    "> 분류(k-NN)와 **코드 구조가 동일**하다. 모델 이름만 바뀌었을 뿐이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 + 학습\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 예측값과 실제값 비교 (처음 10개)\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"실제값\": y_test.values[:10],\n",
    "    \"예측값\": predictions[:10].round(1),\n",
    "    \"오차\": (y_test.values[:10] - predictions[:10]).round(1),\n",
    "})\n",
    "\n",
    "print(\"예측 결과 (처음 10개):\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7. 회귀 평가지표 — MSE · RMSE · R²\n",
    "\n",
    "분류에서는 **정확도(accuracy)** 를 사용했지만,\n",
    "회귀에서는 타겟이 연속형 숫자이므로 다른 평가지표가 필요하다.\n",
    "\n",
    "| 지표 | 수식 | 단위 | 해석 |\n",
    "|------|------|------|------|\n",
    "| **MSE** | 오차²의 평균 | 점² | 0에 가까울수록 좋음 |\n",
    "| **RMSE** | √MSE | 점 | 직관적 해석 가능 |\n",
    "| **R²** | 1 − (모델오차/평균오차) | 비율 | 1에 가까울수록 좋음 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MSE(평균 제곱 오차)와 RMSE(평균 제곱근 오차)를 계산한다.\"\"\"\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"MSE:  {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"\\n해석: 평균적으로 약 {rmse:.1f}점 정도 예측이 빗나갑니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"R² (결정계수)를 계산한다.\n",
    "\n",
    "R² = 1 - (모델 오차 / 평균 오차)\n",
    "- 1에 가까울수록 좋음\n",
    "- 0이면 평균과 동일한 수준\n",
    "- 음수이면 평균보다 못함\n",
    "\"\"\"\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"\\n해석: 모델이 시험점수 변동의 약 {r2 * 100:.1f}%를 설명합니다.\")\n",
    "\n",
    "# R² 값 평가\n",
    "if r2 >= 0.7:\n",
    "    print(\"→ 높은 설명력을 가진 좋은 모델입니다.\")\n",
    "elif r2 >= 0.5:\n",
    "    print(\"→ 중간 수준의 설명력을 가진 모델입니다.\")\n",
    "elif r2 >= 0.3:\n",
    "    print(\"→ 낮은 설명력이지만 피처가 타겟 예측에 어느 정도 도움이 됩니다.\")\n",
    "else:\n",
    "    print(\"→ 매우 낮은 설명력입니다. 피처 선택을 재검토할 필요가 있습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8. 학습된 계수 및 절편 확인\n",
    "\n",
    "- **계수(w)**: 각 피처가 타겟에 미치는 영향력\n",
    "- **절편(b)**: 모든 피처가 0(=평균)일 때의 기준값\n",
    "- ⚠ **주의**: 계수는 \"다른 모든 피처를 고정했을 때\"의 영향력이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"학습된 모델의 계수와 절편을 확인한다.\"\"\"\n",
    "\n",
    "# 계수 DataFrame 생성\n",
    "coef_df = pd.DataFrame({\n",
    "    \"피처\": feature_columns,\n",
    "    \"계수\": model.coef_.round(4),\n",
    "})\n",
    "\n",
    "print(\"계수 (w):\")\n",
    "display(coef_df)\n",
    "print(f\"\\n절편 (b): {model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 계수 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"계수를 해석한다.\n",
    "\n",
    "피처가 표준화되어 있으므로, 계수의 절대값이 클수록 해당 피처가\n",
    "시험점수에 미치는 영향이 크다.\n",
    "\"\"\"\n",
    "\n",
    "# 가장 큰 양수/음수 계수 찾기\n",
    "max_pos_idx = np.argmax(model.coef_)\n",
    "min_neg_idx = np.argmin(model.coef_)\n",
    "\n",
    "print(f\"가장 큰 양수 계수:\")\n",
    "print(f\"  피처: {feature_columns[max_pos_idx]}\")\n",
    "print(f\"  계수: {model.coef_[max_pos_idx]:.4f}\")\n",
    "print(f\"  → 다른 조건이 같을 때, {feature_columns[max_pos_idx]} 1단위 증가 시\")\n",
    "print(f\"    시험점수가 약 {model.coef_[max_pos_idx]:.2f}점 증가\")\n",
    "\n",
    "print(f\"\\n가장 큰 음수 계수:\")\n",
    "print(f\"  피처: {feature_columns[min_neg_idx]}\")\n",
    "print(f\"  계수: {model.coef_[min_neg_idx]:.4f}\")\n",
    "if model.coef_[min_neg_idx] < 0:\n",
    "    print(f\"  → 다른 조건이 같을 때, {feature_columns[min_neg_idx]} 1단위 증가 시\")\n",
    "    print(f\"    시험점수가 약 {abs(model.coef_[min_neg_idx]):.2f}점 감소\")\n",
    "else:\n",
    "    print(f\"  → 모든 계수가 양수입니다.\")\n",
    "\n",
    "# 전체 계수 해석\n",
    "print(f\"\\n각 피처별 해석:\")\n",
    "print(\"-\" * 60)\n",
    "for feature, coef in zip(feature_columns, model.coef_):\n",
    "    direction = \"증가\" if coef > 0 else \"감소\"\n",
    "    print(f\"{feature:12s}: {coef:8.4f}  → {feature} ↑ = 시험점수 {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9. 다중공선성 점검\n",
    "\n",
    "- **다중공선성**: 피처 간 높은 상관 → 계수 해석이 불안정해짐\n",
    "- 상관계수 |r| > 0.5인 피처 쌍을 확인\n",
    "- 예측 성능은 괜찮을 수 있지만, 계수 해석은 위험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"피처 간 상관관계를 확인하여 다중공선성을 점검한다.\"\"\"\n",
    "\n",
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "print(\"상관계수 행렬:\")\n",
    "display(correlation_matrix.round(3))\n",
    "\n",
    "# 높은 상관관계 찾기 (|r| > 0.5)\n",
    "threshold = 0.5\n",
    "print(f\"\\n상관이 높은 피처 쌍 (|r| > {threshold}):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "high_corr_found = False\n",
    "for i in range(len(feature_columns)):\n",
    "    for j in range(i + 1, len(feature_columns)):\n",
    "        r = correlation_matrix.iloc[i, j]\n",
    "        if abs(r) > threshold:\n",
    "            print(f\"{feature_columns[i]:12s} ↔ {feature_columns[j]:12s}  r = {r:6.3f}\")\n",
    "            high_corr_found = True\n",
    "\n",
    "if not high_corr_found:\n",
    "    print(\"(없음)\")\n",
    "    print(\"→ 다중공선성 문제가 심각하지 않습니다.\")\n",
    "else:\n",
    "    print(\"\\n⚠ 주의: 상관이 높은 피처 쌍의 계수는 개별 해석 시 주의가 필요합니다.\")\n",
    "    print(\"  데이터가 조금만 바뀌어도 계수 값이 크게 변할 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 10. 훈련/테스트 성능 비교\n",
    "\n",
    "- 훈련 성능: 이미 본 데이터에 대한 성능 (가짜 실력일 수 있음)\n",
    "- 테스트 성능: 본 적 없는 데이터에 대한 성능 (진짜 실력)\n",
    "\n",
    "| 패턴 | 훈련 | 테스트 | 진단 |\n",
    "|------|------|--------|------|\n",
    "| 양호 | 좋음 | 좋음 (비슷) | ✓ |\n",
    "| 과적합 | 좋음 | 나쁨 (gap 큼) | ⚠ |\n",
    "| 과소적합 | 나쁨 | 나쁨 | ✗ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"훈련 세트와 테스트 세트의 성능을 비교한다.\"\"\"\n",
    "\n",
    "# 훈련 세트 성능\n",
    "train_predictions = model.predict(X_train)\n",
    "train_mse = mean_squared_error(y_train, train_predictions)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_r2 = r2_score(y_train, train_predictions)\n",
    "\n",
    "# 테스트 세트 성능\n",
    "test_mse = mean_squared_error(y_test, predictions)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, predictions)\n",
    "\n",
    "# 결과 출력\n",
    "performance_df = pd.DataFrame({\n",
    "    \"MSE\": [train_mse, test_mse],\n",
    "    \"RMSE\": [train_rmse, test_rmse],\n",
    "    \"R²\": [train_r2, test_r2],\n",
    "}, index=[\"훈련 세트\", \"테스트 세트\"])\n",
    "\n",
    "print(\"성능 비교:\")\n",
    "display(performance_df.round(4))\n",
    "\n",
    "# 일반화 성능 분석\n",
    "print(f\"\\n분석:\")\n",
    "if train_mse < test_mse:\n",
    "    diff_percent = (test_mse - train_mse) / train_mse * 100\n",
    "    print(f\"훈련 MSE < 테스트 MSE (차이: {diff_percent:.1f}%)\")\n",
    "    if diff_percent < 10:\n",
    "        print(\"→ 정상적인 패턴. 일반화 성능이 양호합니다.\")\n",
    "    elif diff_percent < 30:\n",
    "        print(\"→ 약간의 과적합 경향이 있을 수 있습니다.\")\n",
    "    else:\n",
    "        print(\"→ 과적합 가능성이 있습니다. 모델 복잡도 검토가 필요합니다.\")\n",
    "else:\n",
    "    print(\"훈련 MSE ≥ 테스트 MSE\")\n",
    "    print(\"→ 데이터 분할에 따라 발생 가능한 상황입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 11. 최종 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"실습 결과를 요약한다.\"\"\"\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"  3주차 선형 회귀 실습 — 최종 요약\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n데이터셋 정보\")\n",
    "print(f\"  전체 샘플: {len(df):,}개\")\n",
    "print(f\"  훈련 세트: {len(X_train):,}개\")\n",
    "print(f\"  테스트 세트: {len(X_test):,}개\")\n",
    "print(f\"  피처 개수: {len(feature_columns)}개\")\n",
    "\n",
    "print(f\"\\n타겟 변수\")\n",
    "print(f\"  시험점수 ({df[target].min()}~{df[target].max()}점)\")\n",
    "print(f\"  평균: {df[target].mean():.2f}점\")\n",
    "\n",
    "print(f\"\\n모델 성능 (테스트 세트)\")\n",
    "print(f\"  RMSE: {test_rmse:.2f}점\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2 * 100:.1f}% 설명력)\")\n",
    "\n",
    "max_pos_idx = np.argmax(model.coef_)\n",
    "print(f\"\\n주요 발견\")\n",
    "print(f\"  가장 큰 영향: {feature_columns[max_pos_idx]} (계수: {model.coef_[max_pos_idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 학습 정리\n",
    "\n",
    "| # | 핵심 | 설명 |\n",
    "|---|------|------|\n",
    "| 1 | **회귀 평가지표** | MSE (오차²) · RMSE (√MSE, 직관적) · R² (설명력) |\n",
    "| 2 | **계수 해석** | 부호 = 방향, 크기 = \"다른 피처 고정 시\" 영향력 |\n",
    "| 3 | **다중공선성** | 피처 간 높은 상관 → 계수 불안정 (예측은 괜찮을 수 있음) |\n",
    "| 4 | **일반화 성능** | 항상 테스트 세트로 최종 평가! |\n",
    "| 5 | **scikit-learn 패턴** | 분류(k-NN)와 동일한 `fit → predict → score` 구조 |\n",
    "\n",
    "### 주의사항\n",
    "1. 스케일이 다른 피처의 계수는 직접 비교 불가 → **표준화 후 비교**\n",
    "2. 상관이 높은 피처 쌍의 계수 해석 주의 → **다중공선성 점검 필수**\n",
    "3. 이 결과는 `random_state=42`에서의 단일 분할 결과이다\n",
    "   → 더 안정적인 평가: **4주차 교차검증(Cross-Validation)**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
